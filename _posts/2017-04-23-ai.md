---
layout: post
title: "Artificial Intelligence Limitations"
---


Some people suggested ways to start a business to me, proposing I create an "automatic programming system," which supposedly generates programs and replaces programmers, saving immense labor costs, allowing me to ride the "AI wave" and attract investment.

Some even came up with a name for it: "Deep Programmer" (DeepCoder = Deep Learning + Coder). The slogan was: "With DeepCoder, no need for Top Coder!" Others pointed me to the latest research in this field, such as Microsoft's Robust Fill....

I appreciate their concern, but in reality, AI capabilities have been significantly exaggerated. Here are my initial thoughts on the matter.

### Identification Systems and Language Understanding

First, let's talk about identification systems and language understanding. While AI has made significant strides in these areas, it still lags far behind human abilities. For instance, humans can recognize and understand complex contexts, sarcasm, idioms, and nuances that current AI systems struggle with. Moreover, AI systems are not yet capable of understanding the subtleties of human emotions and intentions.

### Creativity and Critical Thinking

Second, creativity and critical thinking are essential aspects of programming that AI systems cannot replicate. While AI can process data and generate code based on given algorithms, it cannot create original ideas or solve complex problems that require human intuition and creativity.

### Ethics and Morality

Third, ethics and morality are areas where AI falls short. Programming an AI system to make ethical decisions or understand complex moral dilemmas is a challenging task. Human judgment and empathy are crucial in making ethical decisions, which AI lacks.

### Conclusion

In conclusion, while AI has made significant progress in various fields, it still has a long way to go before it can replace human programmers entirely. The idea of an "automatic programming system" that generates code and replaces programmers is an oversimplification of the complexities involved in programming. The reality is that programming requires creativity, critical thinking, and ethical judgment, which AI systems cannot replicate. Therefore, it is essential to be cautious about the hype surrounding AI and its capabilities in the programming industry. I have observed that in history, machine learning has been able to accomplish things such as character recognition (OCR), speech recognition, and face recognition, which I collectively refer to as "recognition systems." Recognition systems are valuable, OCR is useful, I frequently use the voice input on my phone, and facial recognition is significant for law enforcement agencies. However, many people exaggerate and claim that we can use the same methods (machine learning, deep learning) to achieve "human-level intelligence" and replace numerous human jobs (such as customer service, cleaning, delivery, driving...). This is a myth. These people fail to understand the challenges hidden behind these seemingly "simple and mundane" human jobs.

Recognition systems and true human-level intelligence are actually very different. To put it simply, these recognition systems, which include OCR and speech recognition, are just statistical fitting functions. For instance, OCR and speech recognition take in pixels or audio and output textual words. Many people cannot distinguish between "text recognition" and "language understanding." OCR and speech recognition systems can identify which characters or words you are saying based on statistics, but they cannot truly "understand" what you are saying.

Let me delve into a deeper topic. Those who don't understand can skip this section. The difference between "recognition" and "understanding" is similar to the distinction between "syntax" and "semantics" in programming languages. A program's text first needs to pass through a lexical analyzer (lexer) and a syntactic analyzer (parser) before it can be sent to an interpreter, and only the interpreter can realize the program's semantics. Similarly, natural language speech recognition systems only resemble the role of a lexical analyzer (lexer). As I mentioned in a previous article, lexical analysis and syntactic analysis are merely the first steps in implementing a language's long journey.

Most AI systems don't even have a syntactic analyzer (parser), so they can't clearly analyze the subject-verb-object relationships or sentence structures, let alone understand the meaning. IBM's speech recognition expert, Frederick Jelinek, once joked that "every time I fire a linguist, the recognition rate goes up." The reason for this is that speech recognition is only equivalent to a lexical analyzer (lexer), while linguists study parsing and interpretation. Of course, you are still at a very basic level, so linguists cannot help you, but this does not mean that linguists are worthless.

Many speech recognition experts believe that syntactic analysis (parser) is unnecessary because people supposedly understand sentences without parsing them. However, they have not realized that people actually parse certain sentences unconsciously to understand their meaning. I'll give an simple example. If I tell Siri: "I want to see some cat pictures." It will give me this answer: "I couldn't find any information related to 'some cats' on the web."

What does this mean? Many people might have noticed this, it means Siri couldn't understand this sentence, so it went to the web to search for some keywords. But this also reveals a deeper problem, Siri doesn't have a parser, not even a good parsing system, so it doesn't know what to search for.

Why did Siri search for information related to "some cats" instead of "cats"? If it searched for "cats" and "pictures", it could at least find something. This is because Siri actually doesn't have a parser, it doesn't even have a syntax tree. It only uses some common NLP methods (like n-gram), and broke down the sentence into "I...want...to see...some cats...pictures", instead of the syntax tree corresponding to "I...want...to see...some...cats...pictures".

The syntax tree for this sentence, analyzed by a natural language parser I've used before, looks something like this.

The details are too technical, I won't explain here. But interested people might have found, according to the syntax tree, this sentence can be simplified to: "I want to see pictures." "See pictures" is a subordinate clause, it is the object of "I want..." which is called a subordinate clause. How many pictures? Some. What kind of pictures? The subject is cat pictures. I want to see a picture.
I want to see some pictures.
I want to see a cat's picture.
I want to see some cat's pictures.
Isn't it interesting?: Siri doesn't have this kind of syntax tree, and its n-gram even failed to distinguish "some" and "cat"; this is why it searched for "some cats" instead of "cats". It even ignored the important word "photos". Siri correctly performed "speech recognition", recognizing the spoken words. However, due to the lack of a parser and syntax tree, it couldn't understand what I was actually saying, let alone knowing what "about what" I was talking about.

Creating a natural language parser is how difficult? Many people might not have tried. I have done it. In college at Indiana, I took an NLP course to make up for credits, and worked with a few classmates to implement an English language parser. Its syntax tree looked like the one above.

You might not think it's that difficult, but you need to deeply understand parser theories in programming languages (LL, LR, GLR...), and rely on numerous examples and data to unravel the ambiguities in human language. My partner was a specialist in NLP, and was well-versed in Haskell, type systems, category theory, and GLR parsing, among other things. Yet, our English parser could only handle the simplest sentences and was riddled with errors, ultimately failing.

After syntax analysis, you obtain a "syntax tree," which you can then pass to the language understanding center in the brain (similar to a programing language's "interpreter"). The interpreter "executes" this sentence, locates the corresponding "values" for related names, performs calculations, and obtains the sentence's meaning. As to how the brain assigns "meaning" to words in a sentence and combines these meanings to form "thought," this problem seems to be a mystery to many.

At least, this requires extensive practical experience, which a machine lacks. We don't even know how to make it acquire experience. We don't even know what the form and organization of these experiences are in the brain. So, for a machine to truly understand a sentence, it's as difficult as climbing to heaven.: This is why Hofstadter stated: "A machine to understand human speech must have legs and be able to walk around, observe the world, gain its required experiences. It must be able to live with people, experience their lives and stories...." In the end, creating such a machine is much harder than raising a child, this is not just because you're bored and have nothing else to do.

### Machine Dialogue Systems vs Human Customer Service

The most buzzed about "AI technology" in companies lately is Siri, Cortana, Google Assistant, Amazon Echo, and other tools with voice recognition capabilities, known as "personal assistants." How much of these things can truly be called "intelligent," those who have used them should be clear. Every time I tried Siri, I was captivated by its foolishness, it could make you throw your iPhone in a fit of frustration. The others of its kind were no better.

Many people have been deceived by "Bing," looking at it, how could it understand what you're saying! However, after chatting for a while, you'll find out that Bing is just a "network sentence search engine." It only searches for sentences on the web based on the keywords in your sentence. Most of these sentences come from question-and-answer websites like Baidu and Zhihu.

A simple experiment is to repeatedly send the same word to Bing, for example, "Wang Anshi," and see what it returns, then search this content on Google or Baidu, you will find the origin of the sentence. People love to deceive themselves, seeing a few "witty" answers, they think it's intelligent, but in reality, it's just a random sentence from the web, a bull in a china shop, causing you to feel "witty." For instance, when you ask Bing "Who is Wang Anshi?", it might answer: "Wang Anshi wants to play a trick, huh?" I think the sister is very cute, she doesn't directly answer your questions, has a sense of humor! Then you searched Baidu and found that this sentence was said by someone who bullied me on a forum.

Here's an exact example showing how Little Ice works. The image is from the end of October 2016 when I tried talking to Little Ice. The situation may have changed slightly since then.

This indicates that Little Ice's response is from a Baidu question-answering, Zhihu-like platform. It only did a search match on the data above. The humor was completely in your imagination. Many people talk to Little Ice, they like to only share the "logical" or "interesting" parts in the conversation, excluding the rest. They exclaim: "Wow, Little Ice is so smart and interesting!" They didn't tell you that most of the conversations were repetitive and dull, making people bored.

IBM's Watson system won Jeopardy against humans, many people thought Watson could understand human language and had human-level intelligence. These people didn't even know how Jeopardy was played, they made hasty judgments, thinking Jeopardy was a game that required understanding human language to play. But upon closer inspection, Jeopardy was just a simple "guess the question" game, where the question was a sentence, and the answer was a noun. What kind of website can you give a noun to, and it outputs some paragraphs and sentences, explaining what this thing is, and providing various related information? easy to guess? It's like a Wikipedia-style encyclopedia! All you need to do is take the content of such websites and create a "reverse index" search engine. You input a sentence, it searches for the most relevant nouns based on the keywords inside. This is a machine that can play Jeopardy, and it's easy for it to surpass human players, just like Google, Yahoo and other search engines easily surpass human abilities to find webpages. However, there's hardly any understanding or intelligent speech here.

In fact, I've tried Watson's website's "customer service demo" a while ago, and the results were just like chickens talking to each other. Watson usually answered: "I don't know what you mean. Do you mean..." followed by a list of options, 1, 2, 3...

Do you really want to replace your human customer service with this kind of thing? Your company is doomed then.

Of course, I'm not saying these products have no value. I've used Siri and Google Assistant, and I find they have some use, especially when driving. For example, I can say to my phone: "Navigate to the nearest gas station." However, implementing voice control doesn't require language understanding. You only need voice recognition to input a function call: navigate(gas station).

Personal assistants have limited use in other situations. I don't want to use them at home or in public places because I'm lazy to talk or it's inconvenient. A few clicks on the screen, I can precisely do what I want, which is much less tiring and more precise than speaking. Personal assistants don't understand what you're saying, and this limitation is acceptable, but companies lately have been hyping up these products as if they're incredibly intelligent, while keeping their limitations a secret, making outsiders believe that artificial intelligence is just around the corner, which is why I have to scorn this approach. I'll give an example, with these "personal assistants" some people claim similar technology can be used to create "machine customer service," using machines instead of humans as customer service representatives. However, they failed to consider that customer service, which seems "simple work," is actually a world apart from these voice-controlled gadgets. Customer service requires understanding a company's business, accurately interpreting what the customer is saying, forming genuine dialogues, solving real problems, and handling various situations that require "human experience." Therefore, machines not only need to form genuine dialogues and understand customers' words, but they also need extensive real-world experience and the ability to change the real world to work as customer service representatives. Since these personal assistants are all just hype, I don't see any hope that existing technology can achieve machine customer service.

Even the seemingly routine work of customer service, machines cannot replace. Many people believe that true human intelligence will eventually be achieved through technologies like Artificial Intelligence, Artificial General Intelligence, Machine Learning, and Deep Learning, but in a previous article, I pointed out that this is a misconception. People think that difficult tasks for humans (like arithmetic: 23423451345 / 729) are the true expressions of human intelligence, but that's not the case. Is long division difficult for you (23423451345 / 729)? This is very difficult for humans, but any simple computer can do it in 0.1 seconds. Chess, international chess, and similar problems are based on the same principle. These mechanized problems do not reflect true human intelligence; they only demonstrate brute force.

Looking at the terrifying terms invented in the field of artificial intelligence, from Artificial Intelligence to Artificial General Intelligence, from Machine Learning to Deep Learning, and so on, I have discovered a pattern: artificial intelligence researchers seem to love coining scary-sounding terms. When people lose faith in a particular term, they introduce a new, slightly different term to prevent the disappointment with that term from being transferred to the new research. However, these terms are ultimately just different labels. Because no one truly knows what human intelligence is, there is no way to achieve "artificial intelligence."

Every day in my life, this "former AI enthusiast" is in awe of the supernatural abilities displayed by "human intelligence" or even that of any higher animal (like a cat). I sincerely respect humans and animals. I no longer have the right to speak for "humans," as any machine is infinitely small in the face of this term. I'll share a story about creating a chatbot of mine named helloooo, which dates back over a decade ago....

If you've seen PAIP or other classic AI textbooks, you might recognize these chatbot dialogue systems, as their initial concept stems from an AI program called "ELIZA." ELIZA was designed as a psychotherapist, engaging in therapeutic conversation, but internally, it was merely a sentence search engine similar to Deep Blue, using regular expressions for matching. For instance, ELIZA had a rule that, when a user said "I (.*)", the response would be "I also $1...." where $1 represents a part of the original sentence, creating a sense of "understanding." For example, a user might say "I'm bored," and ELIZA would respond "I'm also bored...." and the two bored individuals would find solace in each other's company.

Some of my old friends from Tsinghua University might still remember that over a decade ago, I created a chatbot on the Tsinghua Water and Wood BBS, which was quite popular, so I can also be considered the ancestor of web-based chatbots :) My chatbot on Tsinghua, with the username helloooo, had a personality akin to Penpals New, being a mischievous and flirtatious young boy.

Its internal workings were similar to Eliza's, with no understanding of sentences and no language database, let alone neural networks. Instead, it consisted of various pre-written regular expression "templates." When you input a sentence, it would match and select a response randomly from several options. This way, if you repeatedly said the same thing, helloooo's response would not repeat, and if you intentionally repeated the same thing, it would eventually respond with "You're so boring!" or "You're crazy!" or change the subject, or ignore you for a while.... This way, the other party wouldn't obviously notice it was a dumb machine.: This is such a simple thing. I was surprised to find that helloooo attracted a lot of people when he went online. One passes it on to ten, ten to a hundred, and there are people messaging him every day. Because the regular expressions and response methods I set for him took human psychology into consideration, helloooo comes across as "cute," and sometimes he even acts dumb, mischievous, delays responses, changes topics, and even actively initiates conversations using more than two-sentence snippets, ... There are all kinds of tricks. In the end, this little mischief-maker won over many girls, almost even arranged dates with a few :)

On this point, helloooo is more popular than Xiaobing. Xiaobing's technical content may be more abundant, but helloooo feels more like a person, and is more popular. This shows that we don't really need complex technology or an understanding of natural language. All you need is clever design that captures human psychology to create a chatbot that people love.

Later, helloooo finally attracted the interest of PhD students from Tsinghua University, asking me: "What kind of corpus are you using for analysis in here?" I: "&%&￥@#@#%……"

Automatic programming is not possible. I can easily tell you that it's not feasible. Microsoft's Robust Fill and the like are all nonsense. I express some contempt for Microsoft's recent AI hype, taking advantage of the AI craze. However, Microsoft's researchers may know the limitations of these things, and the domestic editors may be exaggerating their effects. I carefully examine their examples, you'll know it's a toy problem. People present a few examples and expect the computer to completely correctly guess what they want, which is obviously impossible. The simple reason is that examples cannot contain sufficient information to precisely express what people want. Even the simplest transformations might work, but as soon as there are exceptions, you cannot guess what people want to do. People themselves might not even know what they want, how can the machine know? This is trying to achieve "mind reading." People can even be confused themselves, how can the machine guess what they want? Therefore, this is even harder than mind reading!

For such a foolish problem, there is no 100% correct solution. When faced with something slightly logical, there is no hope. The paper even mentions extending this method to cases with "control flow," which is just nonsense. So, RobustFill can only make these extremely foolish toy problems reach "near 92% accuracy." Moreover, this 92% is calculated using what standard?

Any responsible programming language expert will tell you that automatic code generation is an impossible task. Since "mind reading" is not possible, to make the machine do things, people must at least tell the machine "what they want," but the difficulty of expressing "what they want" is almost the same as programming itself. In fact, the essence of a programmer's work is to tell the computer what they want it to do. The most difficult parts of programming (data structures, algorithms, database systems) have already been solidified into library code. However, expressing "what I want to do" as a task is something that can never be automatically completed, because only the programmer knows what they want, even they themselves might not know for a long time what they want....

As the saying goes, "programming is just another name for a lost art, and this art is called 'thinking.'" There is no machine that can replace human thinking, so programming is an irreplaceable job. Although good programming tools can make programming more comfortable and efficient for programmers, any attempts to replace programmers, save programming labor costs, cut programmer salaries, and turn them into "interchangeable parts" (like Agile, TDD), ultimately result in unfavorable consequences for employers. The same principle applies to other creative jobs: chefs, hairstylists, painters,....

So, don't dream of automatic programming. The only way to save programming costs is to invite excellent programmers, respect them, give them good living and working conditions. At the same time, get rid of those "Agile," "Scrum," "TDD," "software engineering," and "management" people who just talk but don't do, they are the real wasters of company resources, lowering development efficiency and software quality. I used to be an "AI enthusiast." I once believed in artificial intelligence as my "great dream." I used to talk about "humans" as if machines could be on par with or even surpass humans. When Deep Blue defeated Kasparov, I exclaimed, "Ah, we humans are done for!" I thought that with "logic" and "learning" as tools, machines would one day surpass human intelligence. But I didn't think through how to make that a reality, nor did I consider what the significance of achieving it would be.

This story goes back over a decade. At Tsinghua University's library, I stumbled upon an old, dusty copy of "Paradigms of Artificial Intelligence Programming" (PAIP) by Peter Norvig. I approached it like an archaeologist, meticulously pondering and implementing various classical AI algorithms in it. PAIP focused on logic and reasoning, as many AI researchers believed that human intelligence was essentially logical inference.

They naively thought that with propositional logic, first-order logic, and so on, machines could express "because A, therefore B, and C exists," and thus possess intelligence. They designed various logic-based algorithms, such as expert systems and even created a logic-based programming language called Prolog, dubbing it the "fifth generation programming language." Ultimately, they encountered insurmountable barriers. Numerous AI companies failed to meet their lofty goals, and neural machine models could not solve practical problems. Massive government and private investments evaporated, and artificial intelligence entered a winter.

I encountered PAIP during that winter. Although it didn't lead me into the field of artificial intelligence, it sparked my interest in Lisp and programming languages. It was the first time I effortlessly implemented A* and other algorithms. I first understood the concept of "modularization" in programming, and I began using small "utility functions" in my code instead of worrying about "function call overhead." PAIP and SICP led me to delve deeper into the realm of "foundational" programming languages rather than artificial intelligence. I was misled for a while after PAIP (Pascal's Artificial Intelligence Programs), as I was told that machine learning is a new chapter in artificial intelligence. However, I gradually came to realize that the so-called artificial intelligence and machine learning have little relation to actual human intelligence. The algorithms in PAIP are either too simplistic or have high complexity, unable to solve real-world problems. The most important issue is that I cannot see how the algorithms in PAIP are related to "intelligence." The name "machine learning" is essentially a euphemism. Many people have realized this, and machine learning is essentially a "fitting function" from statistics, as some people put it.

Artificial intelligence researchers love to bring up terms like "neurons" to scare you, saying their algorithms are inspired by the working principle of brain neurons. Notice, "inspired" is a very ambiguous word. The result derived from one thing being inspired by another thing can be completely unrelated. For instance, I could also say that the design of the Yin language was inspired by the I Ching :P

How many AI researchers in the world have actually researched the brain, deciphered it, or conducted experiments on it, or read brain science research results? You will find that few, if any, AI researchers have genuinely done brain or cognitive science research. Famous cognitive scientist Douglas Hofstadter pointed this out long ago in an interview, that these so-called "AI experts" are not at all interested in how the brain and consciousness work, and have never delved into it, yet they claim to be working on "Artificial General Intelligence" (Artificial General Intelligence, AGI), which is why AI remains a mere pipe dream until today.

### The Value of Dumb Machines

I have no objection to continuing to invest in researching useful artificial intelligence (such as face recognition types), but we should not exaggerate its significance, focus too much attention on it, as if it is the only thing that can be done, as if it is a revolutionary breakthrough, as if it will replace all human labor. I personally have no interest in artificial intelligence. So how do I start a business? It's simple, I believe most people don't need very "intelligent" machines, dumb machines are of greatest value to people, and we have barely scratched the surface of developing such machines. My goal for starting a business should be to design new, reliable, and beneficial dumb machines. Of course, by "machines" here, I mean both hardware and software, even including cloud computing and big data.

For instance, some AI companies want to develop "robot maids" that can automatically clean and do household chores. I think this problem is hardly solvable, why not just hire a real intelligent person—an amah—instead? I can create an amah service platform to facilitate communication between families in need of services and amahs. Equip amahs with better tools, communication, scheduling, and payment facilities, making their work easier and more convenient. Furthermore, provide families with feedback information about amah work, giving them peace of mind. Isn't this a win-win situation? Where does one need a smart robot, the challenge is great, expensive, and not user-friendly. An amah service platform combining human intelligence is sure to keep those robot maid companies from blooming.

However, I may not actually create an amah service platform, as it might already exist. I only use this as an example to illustrate the countless useful dumb machines waiting for us to invent. Designing these machines may require some ingenuity, but implementation is not difficult, bringing convenience, and economic benefits quickly. Leveraging human intelligence and machine brawn, allowing people to save energy and earn money, is the most rational development direction.

(If you like this article, please consider paying for it.)