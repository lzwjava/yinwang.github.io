---
layout: post
title: "A new type of operating system design"
---


I have been trying to utilize programming language principles to design an operating system that surpasses the "Unix philosophy." Here is my concept:

- In this system, communication between programs does not use unstructured strings, but rather uses data with types and structures. In such a system, the concept of "applications" in Unix and other similar operating systems (like Windows) essentially disappears. The system is composed of many small "functions," each of which can call another function and pass data through parameters. Each function can be manually or automatically concurrently executed. In terms of current system terminology, this is like all code being "library" code, with no independent "executable files."

- Because parameters are data structures rather than strings, it eliminates the cumbersome encoding and decoding processes in program-to-program communication. "Inter-process communication" becomes effortless. Any function can call another function to handle specific data types, making mechanisms like "OLE embedding" extremely simple.

- All functions are written in the same advanced high-level programming language, so there is no need for function calls to be "translated." There is no risk of errors such as SQL injection, which arise from treating programs as strings.: Due to this language not allowing applications to use "pointer operations," applications cannot generate segfault or similar errors. To prevent malicious users from manually inserting pointer operations in machine code, the system's executing code is not pure machine code but requires further verification and conversion before being executed by hardware. This is somewhat similar to JVM, but it runs directly on hardware, so it needs some functionalities that JVM doesn't have, like automatically swapping data structures in memory to disk and bringing them back when needed.

Because there are no pointer operations, the system can directly use "real mode" for memory management, eliminating the need for modern processors' memory mapping mechanisms and TLB. Memory management granularity is at the level of data structures, not pages. This significantly improves memory access and management efficiency, and simplifies processor design. According to Kent Dybvig's experience, the system's memory usage efficiency is higher than Unix-like systems by several orders of magnitude.

The system is written in the same high-level language as applications, and "system calls" are just calls to another function. Since only these "system driver functions" have references to hardware, and since the system has no pointer operations, user functions cannot bypass system functions to illegally access hardware.

The system doesn't have a Unix-style "command line." Its "shell" is actually just this high-level language's REPL. Users can input various function calls in a visual structuring editing manner to start a process's running. So you don't need to design a separate "buggy language" like Unix to "glue" applications together.

All data is stored as "structures" in a distributed data-sharing space. The same system language can easily be sent to remote machines, calling library code on remote machines, executing any complex querying, indexing actions, and retrieving results. This method efficiently completes database functions, yet it's much simpler than databases. So-called "query languages" (like SQL, Datalog, Gremlin, Cypher) are redundant; they are far less powerful than regular programming languages. Although they claim to let users "ask questions without programming," their optimization is extremely limited and even impossible to achieve, causing more trouble than direct programming. Logic programming languages (like Prolog) face the same problem; their performance drops significantly when dealing with complex queries. So the system doesn't use relational databases, doesn't need SQL, doesn't need NoSQL, and doesn't need Datalog.: Due to all data being structured, there is no common operating system's unstructured "file system". Data structures may be accessed through paths, but paths are not strings or string patterns. The system does not use regular expressions, instead using a data structure similar to NFA for their splitting and combining operations, avoiding issues like incorrect paths formed by concatenating /a/b/ and /c/d into /a/b//c/d.

All data is automatically synced to the disk at appropriate times and undergoes error handling, allowing most data and processes to continue running after a power outage.

Programmers and users barely need to be aware of the existence of "databases" or "file systems". Programs assume they have infinite space and can construct data at will. Depending on hardware capabilities, some manual disk operations may be necessary.

To minimize data movement, the system or user can choose: 1) moving data, or 2) moving processing "processes" based on data location. Programmers don't need to use MapReduce, Hadoop for large-scale parallel computing, but their expressiveness is much stronger as they are all written in the same programming language.

I once thought I was the first to come up with this approach. However, research revealed that many people had already created similar systems. The Lisp Machine seems to be the closest. Oberon is another. IBM System/38 is the oldest in this category. Recently, Microsoft's Singularity and attempts to directly execute JVM and Erlang VM on hardware have emerged.: This article's title is actually wrong, it's not a "new operating system design." It looks new only because we have forgotten what our current operating systems should look like. I should not say it "surpassed Unix philosophy," but rather, so-called Unix philosophy is in fact a historical regression.